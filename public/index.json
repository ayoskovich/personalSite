[{"authors":["admin"],"categories":null,"content":"I strive to be an effective thought partner to deliver actionable insights using technologies like Python, R, SAS, and many others. I am just as comfortable inverting a matrix as I am communicating complex analyses to non-technical stakeholders and am always on the lookout for opportunities to intertwine analytical models with business processes.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I strive to be an effective thought partner to deliver actionable insights using technologies like Python, R, SAS, and many others. I am just as comfortable inverting a matrix as I am communicating complex analyses to non-technical stakeholders and am always on the lookout for opportunities to intertwine analytical models with business processes.","tags":null,"title":"Anthony Yoskovich","type":"authors"},{"authors":[],"categories":[],"content":"\r For the past 4 years I have been studying statistics. Doing lots of practice problems, playing around with data, and reading textbooks. I’ve become a bit more familiar with the statistical way of thinking, how to analyze problems in terms of distributions rather than single numbers, and how to work with uncertainty. As much as I’ve loved this, it has had quite the unexpected consequence in my personal life.\nI find it hard to have an opinion about anything.\r\n Thinking about a data generating process as single shot ocurrences isn’t a good way to frame problems. A better way would be to ask, “What would happen if we did this thing a bunch of times”. When attempting to effectively evaluate hypotheses, thinking about the distribution of events is often more helpful than looking at single occurrences. You don’t hear about clinical trials with 1 patient or a brake pad company testing on 1 car. We want the largest sample possible because it gives us the clearest picture of the population and reduces variability.\n Now back to my life (it is my website after all). Go out to a restaurant and have a bad experience? Well, I’ve only been there once so maybe it was just an off night. Take a new route home from work? Wow that was quick! But wait, I’m not taking into account the time of day or day of the week.\n I can’t help but be reminded of these scenes from Silicon Valley (NSFW language).\n\r\r\r","date":1585180800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585243986,"objectID":"b32b9623f42c46b0ce3d3b37eaa2494f","permalink":"/post/how-statistics-has-ruined-my-ability-to-have-opinions/","publishdate":"2020-03-26T00:00:00Z","relpermalink":"/post/how-statistics-has-ruined-my-ability-to-have-opinions/","section":"post","summary":"A reflection on an unintended consequence of studying statistics.","tags":[],"title":"How Statistics Has Ruined My Ability To Have Opinions","type":"post"},{"authors":[],"categories":[],"content":"\rIn order to build this site, I use blogdown and then I deploy it with Netlify. The nice thing about netlify is that I can have the site as a repo on GitHub, and every time I push changes, the site will update. However, the other day one of my site builds kept failing. This was due to the Hugo version being different on my local machine than the one that is on Netlify.\nLuckily, and probably for the first time in my entire life, I found the answer in the first place I looked! If you are ever getting an error with exit code: 255, set the HUGO_VERSION environment variable (on Netlify) to the Hugo version you have installed locally. It’s pretty easy to check, in Rstudio just:\nblogdown::hugo_version()\rThis should output a string (mine was ‘0.60.1’) and that string should be the environment variable. More info on setting the evironment variable here.\n","date":1583539200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585243695,"objectID":"c000d08842e43ff1e7c996f3ca6b8cdc","permalink":"/post/hugo-version-problems/","publishdate":"2020-03-07T00:00:00Z","relpermalink":"/post/hugo-version-problems/","section":"post","summary":"Failing netlify builds? Make sure to check the HUGO_VERSION environment variable.","tags":[],"title":"HUGO_VERSION problems","type":"post"},{"authors":[],"categories":[],"content":" Lets say I have the following function, and for some weird reason I want it to be called twice every time I call it.\ndef foo():\rprint('hello')\r  I could solve this in a couple of different ways.\ndef foo():\rprint('hello')\rprint('hello')\r def foo()\rprint('hello')\rfoo()\rfoo()\r  So\u0026hellip;the first way is bad because if I want to extend this functionality to other funtions, I would have to copy and paste the code everywhere. Also, to switch it on and off would be a mess. The second way is even clunkier.\n This is where decorators come in handy. I can write a function, that takes in a function as an argument, and then modify that function. Here\u0026rsquo;s what it looks like:\ndef doTwice(function):\rdef wrapper(*args, **args):\rfunction()\rfunction()\rreturn wrapper\r  Let\u0026rsquo;s break down what\u0026rsquo;s going on here.\n The doTwice function first takes in another function as an argument. There is a function inside of it, called wrapper, that simply calls function twice. doTwice returns wrapper, which is actually a function.   Now that we have the doTwice function, we\u0026rsquo;ll need to use it to \u0026ldquo;decorate\u0026rdquo; the foo function. The syntax in python is simple.\n@doTwice\rdef foo():\rprint('hello')\r  Now, every time I call foo, \u0026lsquo;hello\u0026rsquo; will be printed twice, mission accomplished. The beauty of this solution is that I can now use doTwice on as many functions as I\u0026rsquo;d like. I would simply add @doTwice above each function definition.\n There are tons more helpful things you can do with decorators, and I think in the future I\u0026rsquo;ll write some more posts about them. Thanks for reading!\n Note: The @ syntax isn\u0026rsquo;t the only way to decorate functions, the python documentation lays out another way that requires a bit more explaining.\n","date":1583280000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585245103,"objectID":"d7b1a41d58bdc19a33308126895fb66c","permalink":"/post/a-handy-use-of-decorators-in-python/","publishdate":"2020-03-04T00:00:00Z","relpermalink":"/post/a-handy-use-of-decorators-in-python/","section":"post","summary":"Need a function that takes a function as its argument and returns a function? Look no further.","tags":[],"title":"A handy use of decorators in python","type":"post"},{"authors":null,"categories":null,"content":" When working with data, there are a lot of things I need to keep track of in my head.\n How many observations do I have in total? I just filtered some out, how many did I throw out? Am I aggregating before or after I filter? Where should I add this chunk of code?   In order to keep track of these questions when working in a jupyter notebook I end up having tons of cells that look like this:\ndf.head()\r or\ndf.shape\r  By using decorators and the .pipe method I can develop an analysis path that will give me customized output and automate this tedious cycle of .head() and .shape. Let\u0026rsquo;s take a look.\nimport pandas as pd\rimport numpy as np\rimport functools\rnp.random.seed(5)\rdf = pd.DataFrame({\r'group':np.random.choice(['a', 'b', 'c'], 10),\r'x':np.random.randint(0, 10, 10),\r'y':np.random.normal(0, 10, 10)\r}); df.head()\r \r.dataframe tbody tr th:only-of-type {\rvertical-align: middle;\r}\r.dataframe tbody tr th {\rvertical-align: top;\r}\r.dataframe thead th {\rtext-align: right;\r}\r \n\r\rgroup\rx\ry\r\r\r\r\r0\rc\r0\r9.118736\r\r\r1\rb\r7\r-14.438416\r\r\r2\rc\r1\r18.244402\r\r\r3\rc\r5\r14.576251\r\r\r4\ra\r7\r-9.102582\r\r\r\r\rNow I\u0026rsquo;ll define some processing functions.  These functions all take the dataframe as an argument and pass the dataframe back. A few notes:\n The pDoc decorator is what allows me to print out the docstring and the shapes of the df at each step of the process. The startPipe function may seem useless, but I\u0026rsquo;m just using it the get the size of the dataframe at the beginning of the analysis path.  def pDoc(func):\r\u0026quot;\u0026quot;\u0026quot;Print the docstring of a function.\u0026quot;\u0026quot;\u0026quot;\r@functools.wraps(func)\rdef wrapper(*args, **kwargs):\rrv = func(*args, **kwargs)\rprint(\u0026quot;{}(): \\n\\t{} -\u0026gt; {}\u0026quot;.format(func.__name__, func.__doc__, rv.shape))\rreturn rv\rreturn wrapper\r@pDoc\rdef startPipe(df):\r\u0026quot;\u0026quot;\u0026quot;Begin pipeline\u0026quot;\u0026quot;\u0026quot;\rreturn df\r@pDoc\rdef filterGroups(df):\r\u0026quot;\u0026quot;\u0026quot;Remove group b from the analysis.\u0026quot;\u0026quot;\u0026quot;\rreturn df.query('group != \u0026quot;b\u0026quot;')\r@pDoc\rdef capVal(df):\r\u0026quot;\u0026quot;\u0026quot;Cap the value of y at 10.\u0026quot;\u0026quot;\u0026quot;\rdat = df.copy()\rdat['y'] = dat['y'].apply(lambda x: 10 if x \u0026gt; 10 else x)\rreturn dat\r@pDoc\rdef getMean(df):\r\u0026quot;\u0026quot;\u0026quot;Add column as mean value of x by group.\u0026quot;\u0026quot;\u0026quot;\rdat = df.copy()\rdat['g_mean'] = dat.groupby('group')['x'].transform(np.mean)\rreturn dat\r  Now I\u0026rsquo;ll tie all these functions together using .pipe.\n(df\r.pipe(startPipe)\r.pipe(filterGroups)\r.pipe(getMean)\r.pipe(capVal)).head()\r startPipe(): Begin pipeline -\u0026gt; (10, 3)\rfilterGroups(): Remove group b from the analysis. -\u0026gt; (8, 3)\rgetMean(): Add column as mean value of x by group. -\u0026gt; (8, 4)\rcapVal(): Cap the value of y at 10. -\u0026gt; (8, 4)\r \r.dataframe tbody tr th:only-of-type {\rvertical-align: middle;\r}\r.dataframe tbody tr th {\rvertical-align: top;\r}\r.dataframe thead th {\rtext-align: right;\r}\r \n\r\rgroup\rx\ry\rg_mean\r\r\r\r\r0\rc\r0\r9.118736\r3.0\r\r\r2\rc\r1\r10.000000\r3.0\r\r\r3\rc\r5\r10.000000\r3.0\r\r\r4\ra\r7\r-9.102582\r3.5\r\r\r6\ra\r1\r-8.175481\r3.5\r\r\r\r\r As you can see, I get a really nice log output that shows the function name, docstring, and the shape of its output. I like this solution because it automates the really tedious process of having to ask myself \u0026ldquo;how many records did I just throw out\u0026rdquo;. By using decorators, the function will always show me the shape of the output.\n Also, this solution can be really easily extended / modified. Don\u0026rsquo;t like what my pDoc decorator is doing? It\u0026rsquo;s really easy to change and customize. You\u0026rsquo;re really only limited by your imagination (and python).\n ","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"49bbf573815f7c6bc9dbd0e8338c206d","permalink":"/post/custom-logging/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/post/custom-logging/","section":"post","summary":"By using decorators and the .pipe method I can create an analysis path that easily documents itself.","tags":null,"title":"Custom logging in python","type":"post"},{"authors":null,"categories":null,"content":"Merging summary statistics back into a table is quite a common thing to do. At first glance, a solution to this problem is to simply compute the statistics in a new table and merge the table back in. However, with pandas we don\u0026rsquo;t have to do that.\nimport pandas as pd\rimport numpy as np\rnp.random.seed(124)\rdf = pd.DataFrame({\r'group':np.random.choice(['a', 'b'], 5),\r'x':np.random.randint(100, 200, 5)\r}).sort_values(by='group'); df\r \r.dataframe tbody tr th:only-of-type {\rvertical-align: middle;\r}\r.dataframe tbody tr th {\rvertical-align: top;\r}\r.dataframe thead th {\rtext-align: right;\r}\r \n\r\rgroup\rx\r\r\r\r\r0\ra\r141\r\r\r1\ra\r164\r\r\r4\ra\r178\r\r\r2\rb\r120\r\r\r3\rb\r128\r\r\r\r\rHere I\u0026rsquo;ve got some rows that having a grouping column called group, and I\u0026rsquo;d like to calculate the sum of x within each group and integrate it into my table.\ndf['g_sum'] = df.groupby('group')['x'].transform(np.sum); df\r \r.dataframe tbody tr th:only-of-type {\rvertical-align: middle;\r}\r.dataframe tbody tr th {\rvertical-align: top;\r}\r.dataframe thead th {\rtext-align: right;\r}\r \n\r\rgroup\rx\rg_sum\r\r\r\r\r0\ra\r141\r483\r\r\r1\ra\r164\r483\r\r\r4\ra\r178\r483\r\r\r2\rb\r120\r248\r\r\r3\rb\r128\r248\r\r\r\r\rA key idea is that .transform will apply its function argument to the dataframe and return a result that is the same size as the input frame.\nWe can also use .transform with a user defined function def max_minus_one(col):\r\u0026quot;\u0026quot;\u0026quot; Get the max - 1 of a list\u0026quot;\u0026quot;\u0026quot;\rreturn np.max(col) - 1\rdf['udf'] = df.groupby('group')['x'].transform(max_minus_one); df\r \r.dataframe tbody tr th:only-of-type {\rvertical-align: middle;\r}\r.dataframe tbody tr th {\rvertical-align: top;\r}\r.dataframe thead th {\rtext-align: right;\r}\r \n\r\rgroup\rx\rg_sum\rudf\r\r\r\r\r0\ra\r141\r483\r177\r\r\r1\ra\r164\r483\r177\r\r\r4\ra\r178\r483\r177\r\r\r2\rb\r120\r248\r127\r\r\r3\rb\r128\r248\r127\r\r\r\r\r\u0026hellip;and even lambda functions df['use_lam'] = df.groupby('group')['x'].transform(lambda x: np.max(x) - 1); df\r \r.dataframe tbody tr th:only-of-type {\rvertical-align: middle;\r}\r.dataframe tbody tr th {\rvertical-align: top;\r}\r.dataframe thead th {\rtext-align: right;\r}\r \n\r\rgroup\rx\rg_sum\rudf\ruse_lam\r\r\r\r\r0\ra\r141\r483\r177\r177\r\r\r1\ra\r164\r483\r177\r177\r\r\r4\ra\r178\r483\r177\r177\r\r\r2\rb\r120\r248\r127\r127\r\r\r3\rb\r128\r248\r127\r127\r\r\r\r\r","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567296000,"objectID":"0ea59b7fee420cc5e57d3eb1f5c4456f","permalink":"/post/transform/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/post/transform/","section":"post","summary":"Want to remerge a summary statistic back into a table? Stay away from `pd.merge`...","tags":null,"title":"Effective .transform in python","type":"post"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"}]
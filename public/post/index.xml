<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Anthony Yoskovich</title>
    <link>/post/</link>
    <description>Recent content in Posts on Anthony Yoskovich</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 07 Mar 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>HUGO_VERSION problems</title>
      <link>/post/2020/03/07/hugo-version-problems/</link>
      <pubDate>Sat, 07 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/03/07/hugo-version-problems/</guid>
      <description>&amp;emsp; In order to build this site, I use blogdown and then I deploy it with Netlify. The nice thing about netlify is that I can have the site as a repo on GitHub, and every time I push changes, the site will update. However, the other day one of my site builds kept failing. This was due to the Hugo version being different on my local machine than the one that is on Netlify.</description>
    </item>
    
    <item>
      <title>Using pandas&#39; `.transform()`</title>
      <link>/post/2020/03/06/the-beauty-of-transform/</link>
      <pubDate>Fri, 06 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/03/06/the-beauty-of-transform/</guid>
      <description>&amp;emsp; Suppose I have a dataframe, and I&amp;rsquo;d like to compute the sum of a variable by group, but I&amp;rsquo;d like to keep this sum in the original table. I could solve this by computing the sum and then merging this table back into the original, but I have to either create a new dataset or overload pd.merge with a horrible block of code.
&amp;emsp; Luckily, there is a function in pandas called .</description>
    </item>
    
    <item>
      <title>A Match Made In Heaven</title>
      <link>/post/2020/03/05/applying-complicated-conditionals-to-pandas-dataframes/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/03/05/applying-complicated-conditionals-to-pandas-dataframes/</guid>
      <description>&amp;emsp; Custom logging can be done in python using 2 main things, decorators and the .pipe() function in pandas. I recently worked on a project where there was a large amount of investigation happening. I needed an easy way to toggle filters on and off, post-process in different ways, and change the output format of a dataframe quickly.
The main chain of events is shown below:
final = ( readDat() .</description>
    </item>
    
    <item>
      <title>Generating points with a specific correlation</title>
      <link>/post/2020/03/05/generating-points-with-a-specific-correlation/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/03/05/generating-points-with-a-specific-correlation/</guid>
      <description>Sometimes when playing around with statistical techniques, I&amp;rsquo;d like to generate some data that is correlated. How might I do this? The answer is relatively simple but requires a tad bit of linear algebra.
First, we&amp;rsquo;ll sample from a bivariate normal distribution.
Then, we&amp;rsquo;ll rotate the data points to our specified correlation.
See here:
http://www.acooke.org/random.pdf</description>
    </item>
    
    <item>
      <title>A Handy Use of Python Decorators</title>
      <link>/post/2020/03/04/something-cool-in-python/</link>
      <pubDate>Wed, 04 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/03/04/something-cool-in-python/</guid>
      <description>Lets say I have the following function, and for some weird reason I want it to be called twice every time I call it.
def foo(): print(&#39;hello&#39;)  I could solve this in a couple of different ways.
def foo(): print(&#39;hello&#39;) print(&#39;hello&#39;)  def foo() print(&#39;hello&#39;) foo() foo()  So&amp;hellip;the first way is bad because if I want to extend this functionality to other funtions, I would have to copy and paste the code everywhere.</description>
    </item>
    
    <item>
      <title>Peter Kennedy Doesn&#39;t Think Undergraduates Understand Sampling Distributions</title>
      <link>/post/2020/03/03/peter-kennedy-doesn-t-think-undergraduates-understand-sampling-distributions/</link>
      <pubDate>Tue, 03 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020/03/03/peter-kennedy-doesn-t-think-undergraduates-understand-sampling-distributions/</guid>
      <description>&amp;emsp; In May of 1998, Peter Kennedy wrote a paper in the American Economic Review discussing teaching undergraduate econometrics. In it, he claims that most students don’t understand sampling distributions and puts forth reasons for this thought. In the paper he emphasizes the importance of simulations and suggests a simple one. I’ll be working through his example using R. Here is his suggested example:
  Draw 50 x values from a uniform distribution between 3 and 12.</description>
    </item>
    
  </channel>
</rss>